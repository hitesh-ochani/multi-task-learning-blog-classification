{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6383\n"
     ]
    }
   ],
   "source": [
    "from xml.etree import ElementTree\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DIR= \"/Users/hiteshochani/stat_nlp/project/blog/blogs\"\n",
    "error_count = 0\n",
    "file_count = 0\n",
    "parser1 = ElementTree.XMLParser(encoding=\"ascii\")\n",
    "\n",
    "header_x = \"text\\n\"\n",
    "header_y = \"gender,age,industry,horroscope\\n\"\n",
    "f1 = open('posts.csv','w')\n",
    "f2 = open('labels.csv','w')\n",
    "\n",
    "f1.write(header_x) \n",
    "f2.write(header_y) \n",
    "\n",
    "\n",
    "for file in os.listdir(DIR):\n",
    "    metadata = file.split('.')[:-1]\n",
    "    file_count +=1\n",
    "    try:\n",
    "        root = ElementTree.parse(DIR+'/'+file).getroot()\n",
    "        text = \"\"\n",
    "        for post in root.findall('post'):\n",
    "            text+=post.text.strip()+' '\n",
    "        f1.write(text.replace('\\n', ' ').replace('\\r', '')+'\\n')\n",
    "        f2.write(\",\".join(metadata) +'\\n')\n",
    "            \n",
    "            \n",
    "    except ElementTree.ParseError as p:\n",
    "        error_count+=1\n",
    "#         print(p, end=\"\")\n",
    "#         print(\" \" + file)\n",
    "#         content = \"\"\n",
    "#         with open(DIR+'/'+file, \"rb\") as fin:\n",
    "#             content = fin.read()\n",
    "#             content = re.sub(b'[^\\x00-\\x7F]+',b'', content)\n",
    "#             content = re.sub(b'&[a-z]+;',b' ', content)\n",
    "\n",
    "#         with open(DIR+'/'+file, \"wb\") as fout:\n",
    "#                 foo = content.replace(b'&', b'and')\n",
    "#                 fout.write(foo)\n",
    "f1.close()\n",
    "f2.close()\n",
    "print(error_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiteshochani/anaconda3/envs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_x = pd.read_csv(\"posts.csv\", sep=\"wubbalubbadbdb\")\n",
    "df_y = pd.read_csv(\"labels.csv\")\n",
    "df_input_text = df_x[:25]\n",
    "df_output = df_y[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute embeddings here\n",
    "import torch\n",
    "import torchtext.vocab as vocab\n",
    "glove = vocab.GloVe(name='6B', dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_emb_func = lambda x: glove[x]\n",
    "#frame.apply(f)\n",
    "# # print(df_input_text.iloc[0][0])\n",
    "\n",
    "# import string\n",
    "# first_text = df_input_text.iloc[0][0]\n",
    "# text = df_input_text.iloc[0][0].translate(str.maketrans('','',string.punctuation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(first_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for one sentence, calculate embeddings and context vector.\n",
    "import corenlp\n",
    "import os\n",
    "os.environ['CORENLP_HOME'] = \"/Users/hiteshochani/stat_nlp/project/stanford-corenlp-full-2018-10-05\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DESTINY',\n",
       "  '...',\n",
       "  'you',\n",
       "  'might',\n",
       "  'not',\n",
       "  'say',\n",
       "  'anything',\n",
       "  'but',\n",
       "  'i',\n",
       "  'can',\n",
       "  'hear',\n",
       "  'you',\n",
       "  'have',\n",
       "  'chosen',\n",
       "  'me',\n",
       "  ',',\n",
       "  'your',\n",
       "  'life',\n",
       "  'partner',\n",
       "  'so',\n",
       "  'have',\n",
       "  'i',\n",
       "  'dear',\n",
       "  ',',\n",
       "  'so',\n",
       "  'have',\n",
       "  'i',\n",
       "  'dear',\n",
       "  '...',\n",
       "  '.'],\n",
       " ['my',\n",
       "  'first',\n",
       "  'dream',\n",
       "  ',',\n",
       "  'my',\n",
       "  'first',\n",
       "  'extreme',\n",
       "  ',',\n",
       "  'my',\n",
       "  'first',\n",
       "  'love',\n",
       "  ',',\n",
       "  'i',\n",
       "  'was',\n",
       "  'waiting',\n",
       "  'for',\n",
       "  'my',\n",
       "  'DESTINY',\n",
       "  '.'],\n",
       " ['what',\n",
       "  'should',\n",
       "  'i',\n",
       "  'do',\n",
       "  'with',\n",
       "  'myself',\n",
       "  ',',\n",
       "  'tell',\n",
       "  'me',\n",
       "  'o',\n",
       "  \"'\",\n",
       "  'my',\n",
       "  'heart',\n",
       "  'what',\n",
       "  'should',\n",
       "  'i',\n",
       "  'do',\n",
       "  'with',\n",
       "  'myself',\n",
       "  ',',\n",
       "  'tell',\n",
       "  'me',\n",
       "  '...',\n",
       "  '.'],\n",
       " ['should', 'i', 'fly', ',', 'with', 'this', 'beautiful', 'nature', '.'],\n",
       " ['or', 'should', 'i', 'play', 'with', 'these', 'winds', '.'],\n",
       " ['should',\n",
       "  'i',\n",
       "  'try',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'the',\n",
       "  'skies',\n",
       "  ',',\n",
       "  'or',\n",
       "  'should',\n",
       "  'i',\n",
       "  'pray',\n",
       "  'to',\n",
       "  'the',\n",
       "  'mother',\n",
       "  'earth',\n",
       "  '.'],\n",
       " ['what',\n",
       "  'should',\n",
       "  'i',\n",
       "  'do',\n",
       "  'with',\n",
       "  'myself',\n",
       "  'friends',\n",
       "  'tell',\n",
       "  'me',\n",
       "  '...',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'talked',\n",
       "  'in',\n",
       "  'such',\n",
       "  'a',\n",
       "  'way',\n",
       "  ',',\n",
       "  'gave',\n",
       "  'me',\n",
       "  'dreams',\n",
       "  'with',\n",
       "  'thousand',\n",
       "  'colours',\n",
       "  '.'],\n",
       " ['like',\n",
       "  'i',\n",
       "  'stand',\n",
       "  'in',\n",
       "  'the',\n",
       "  'middle',\n",
       "  'of',\n",
       "  'island',\n",
       "  ',',\n",
       "  'and',\n",
       "  'she',\n",
       "  'shows',\n",
       "  'me',\n",
       "  'all',\n",
       "  'the',\n",
       "  'love',\n",
       "  'she',\n",
       "  'has',\n",
       "  ',',\n",
       "  'my',\n",
       "  'first',\n",
       "  'dream',\n",
       "  ',',\n",
       "  'my',\n",
       "  'first',\n",
       "  'extreme',\n",
       "  ',',\n",
       "  'my',\n",
       "  'first',\n",
       "  'love',\n",
       "  ',',\n",
       "  'i',\n",
       "  'was',\n",
       "  'waiting',\n",
       "  'for',\n",
       "  'my',\n",
       "  'DESTINY',\n",
       "  '.'],\n",
       " ['--', 'NIL', 'DEAR', 'ANGEL', '.'],\n",
       " ['.'],\n",
       " ['you',\n",
       "  'say',\n",
       "  'it',\n",
       "  'or',\n",
       "  'you',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  ',',\n",
       "  'but',\n",
       "  'i',\n",
       "  'can',\n",
       "  'see',\n",
       "  'it',\n",
       "  'in',\n",
       "  'your',\n",
       "  'eyes',\n",
       "  ',',\n",
       "  'some',\n",
       "  'words',\n",
       "  'are',\n",
       "  'not',\n",
       "  'worth',\n",
       "  'saying',\n",
       "  ',',\n",
       "  'they',\n",
       "  'try',\n",
       "  'to',\n",
       "  'remain',\n",
       "  'in',\n",
       "  'your',\n",
       "  'heart',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'saw',\n",
       "  'it',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'inj',\n",
       "  'your',\n",
       "  'eyes',\n",
       "  ',',\n",
       "  'what',\n",
       "  'were',\n",
       "  'you',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'say',\n",
       "  'from',\n",
       "  'your',\n",
       "  'smile',\n",
       "  '.'],\n",
       " ['this',\n",
       "  'lovely',\n",
       "  'destiny',\n",
       "  'was',\n",
       "  'like',\n",
       "  'a',\n",
       "  'game',\n",
       "  'for',\n",
       "  'me',\n",
       "  ',',\n",
       "  'strategy',\n",
       "  ',',\n",
       "  'logic',\n",
       "  ',',\n",
       "  'moves',\n",
       "  'everything',\n",
       "  'it',\n",
       "  'had',\n",
       "  'for',\n",
       "  'me',\n",
       "  ',',\n",
       "  'this',\n",
       "  'wild',\n",
       "  'game',\n",
       "  'was',\n",
       "  'great',\n",
       "  'to',\n",
       "  'play',\n",
       "  ',',\n",
       "  'but',\n",
       "  'as',\n",
       "  'per',\n",
       "  'rules',\n",
       "  ',',\n",
       "  'for',\n",
       "  'every',\n",
       "  'wrong',\n",
       "  'move',\n",
       "  'i',\n",
       "  'have',\n",
       "  'to',\n",
       "  'pay',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'paying',\n",
       "  'for',\n",
       "  'the',\n",
       "  'move',\n",
       "  'i',\n",
       "  'made',\n",
       "  'long',\n",
       "  'ago',\n",
       "  ',',\n",
       "  'but',\n",
       "  'now',\n",
       "  'i',\n",
       "  'love',\n",
       "  'her',\n",
       "  'even',\n",
       "  'much',\n",
       "  'more',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'have',\n",
       "  'seen',\n",
       "  'the',\n",
       "  'world',\n",
       "  'around',\n",
       "  'beautiful',\n",
       "  'oceans',\n",
       "  ',',\n",
       "  'just',\n",
       "  'like',\n",
       "  'your',\n",
       "  'eyes',\n",
       "  '.'],\n",
       " ['beautiful', 'flowers', ',', 'just', 'like', 'your', 'smile', '.'],\n",
       " ['life', 'goes', 'on', 'miles', 'and', 'miles', '.'],\n",
       " ['.'],\n",
       " ['share',\n",
       "  'your',\n",
       "  'kindness',\n",
       "  ',',\n",
       "  'share',\n",
       "  'your',\n",
       "  'smile',\n",
       "  'life',\n",
       "  'goes',\n",
       "  'on',\n",
       "  'miles',\n",
       "  'amd',\n",
       "  'miles',\n",
       "  '.'],\n",
       " ['.'],\n",
       " ['life',\n",
       "  'in',\n",
       "  'not',\n",
       "  'a',\n",
       "  'play',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'full',\n",
       "  'of',\n",
       "  'dangers',\n",
       "  ',',\n",
       "  'take',\n",
       "  'care',\n",
       "  'sweetheart',\n",
       "  ',',\n",
       "  'take',\n",
       "  'care',\n",
       "  'DEAR',\n",
       "  'ANGEL',\n",
       "  '.'],\n",
       " ['--',\n",
       "  'NIL',\n",
       "  'MAIN',\n",
       "  'AUR',\n",
       "  'MERI',\n",
       "  'TANHAI',\n",
       "  '-LRB-',\n",
       "  'jagjeet',\n",
       "  'singh',\n",
       "  '-RRB-',\n",
       "  'awara',\n",
       "  'hai',\n",
       "  'galiyon',\n",
       "  'mein',\n",
       "  ',',\n",
       "  'main',\n",
       "  'aur',\n",
       "  'meri',\n",
       "  'tanhai',\n",
       "  '.'],\n",
       " ['jaye',\n",
       "  'to',\n",
       "  'kaha',\n",
       "  'jaye',\n",
       "  'hum',\n",
       "  ',',\n",
       "  'har',\n",
       "  'mod',\n",
       "  'pe',\n",
       "  'ruswaii',\n",
       "  ',',\n",
       "  'main',\n",
       "  'aur',\n",
       "  'meri',\n",
       "  'tanhai',\n",
       "  '.'],\n",
       " ['yeh', 'phool', 'se', 'chehre', 'hai', ',', 'haste', 'hue', 'guldaste', '.'],\n",
       " ['koi',\n",
       "  'bhi',\n",
       "  'nahi',\n",
       "  'apna',\n",
       "  ',',\n",
       "  'begane',\n",
       "  'hue',\n",
       "  'sab',\n",
       "  'raste',\n",
       "  ',',\n",
       "  'rahe',\n",
       "  'bhi',\n",
       "  'bhi',\n",
       "  'tamasha',\n",
       "  'hi',\n",
       "  ',',\n",
       "  'main',\n",
       "  'aur',\n",
       "  'meri',\n",
       "  'tanhai',\n",
       "  '.'],\n",
       " ['armaan', 'sulagte', 'hain', ',', 'seene', 'mein', 'chita', 'jaise', '.'],\n",
       " ['kaatil', 'nazar', 'ati', 'hai', ',', 'duniya', 'ki', 'hawa', 'jaise', '.'],\n",
       " ['roti', 'hai', 'mere', 'dil', 'par', ',', 'bajti', 'hui', 'shehnai', '.'],\n",
       " ['main', 'aur', 'meri', 'tanhai', '.'],\n",
       " ['akash',\n",
       "  'ke',\n",
       "  'maathe',\n",
       "  'par',\n",
       "  ',',\n",
       "  'taaron',\n",
       "  'ka',\n",
       "  'chala',\n",
       "  'gum',\n",
       "  'hai',\n",
       "  '.'],\n",
       " ['pehlu',\n",
       "  'mein',\n",
       "  'magar',\n",
       "  'mere',\n",
       "  ',',\n",
       "  'zakhmon',\n",
       "  'ka',\n",
       "  'gulistan',\n",
       "  'hain',\n",
       "  '.'],\n",
       " ['aankhon',\n",
       "  'se',\n",
       "  'lahoo',\n",
       "  'tak',\n",
       "  'ka',\n",
       "  ',',\n",
       "  'daaman',\n",
       "  'mein',\n",
       "  'bahar',\n",
       "  'aayi',\n",
       "  ',',\n",
       "  'main',\n",
       "  'aur',\n",
       "  'meri',\n",
       "  'tanhai',\n",
       "  '.'],\n",
       " ['--',\n",
       "  'js',\n",
       "  '-LRB-',\n",
       "  'R',\n",
       "  '-RRB-',\n",
       "  'mail',\n",
       "  'addressrs',\n",
       "  '-LRB-',\n",
       "  's',\n",
       "  '-RRB-',\n",
       "  'urlLink',\n",
       "  'http://rediff.com',\n",
       "  'urlLink',\n",
       "  'http://sify.com',\n",
       "  'urlLink',\n",
       "  'http://indiatimes.com',\n",
       "  'urlLink',\n",
       "  'http://hotmail.com',\n",
       "  'urlLink',\n",
       "  'http://yahoo.com',\n",
       "  'wallpaper',\n",
       "  '-LRB-',\n",
       "  's',\n",
       "  '-RRB-',\n",
       "  'urlLink',\n",
       "  'http://indiafm.com',\n",
       "  'urlLink',\n",
       "  'http://wallpapers.com',\n",
       "  'RAP',\n",
       "  '-',\n",
       "  'ALLRISE',\n",
       "  'so',\n",
       "  'stand',\n",
       "  'back',\n",
       "  'cause',\n",
       "  'u',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'notice',\n",
       "  'catch',\n",
       "  'i',\n",
       "  \"'m\",\n",
       "  'wobin',\n",
       "  'down',\n",
       "  'back',\n",
       "  'u',\n",
       "  'don',\n",
       "  'want',\n",
       "  'me',\n",
       "  'to',\n",
       "  'react',\n",
       "  'i',\n",
       "  'lay',\n",
       "  'low',\n",
       "  'if',\n",
       "  'u',\n",
       "  'know',\n",
       "  'my',\n",
       "  'heart',\n",
       "  'is',\n",
       "  'open',\n",
       "  'the',\n",
       "  'decision',\n",
       "  'of',\n",
       "  'the',\n",
       "  'jury',\n",
       "  'has',\n",
       "  'not',\n",
       "  'been',\n",
       "  'spoken',\n",
       "  'step',\n",
       "  'in',\n",
       "  'my',\n",
       "  'houseu',\n",
       "  \"'ll\",\n",
       "  'find',\n",
       "  'that',\n",
       "  'ure',\n",
       "  'stuff',\n",
       "  'is',\n",
       "  'gone',\n",
       "  'but',\n",
       "  'in',\n",
       "  'reality',\n",
       "  'the',\n",
       "  'room',\n",
       "  'will',\n",
       "  'stop',\n",
       "  'me',\n",
       "  'long',\n",
       "  'i',\n",
       "  'bring',\n",
       "  'you',\n",
       "  'woods',\n",
       "  'of',\n",
       "  'cot',\n",
       "  'to',\n",
       "  'to',\n",
       "  'push',\n",
       "  'my',\n",
       "  'order',\n",
       "  'and',\n",
       "  'you',\n",
       "  'know',\n",
       "  'that',\n",
       "  'you',\n",
       "  'over',\n",
       "  'step',\n",
       "  'the',\n",
       "  'border',\n",
       "  'aha',\n",
       "  '...',\n",
       "  '!!!!!!!!!!'],\n",
       " ['--', 'blues', 'MISSING', 'YOU', 'BADLY', '.'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'lonely',\n",
       "  'here',\n",
       "  ',',\n",
       "  'searching',\n",
       "  'you',\n",
       "  'everywhere',\n",
       "  ',',\n",
       "  'life',\n",
       "  'is',\n",
       "  'where',\n",
       "  '...',\n",
       "  '.'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'i',\n",
       "  'can',\n",
       "  'see',\n",
       "  'only',\n",
       "  'you',\n",
       "  'wherever',\n",
       "  'i',\n",
       "  'see',\n",
       "  '...',\n",
       "  'i',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'sleep',\n",
       "  ',',\n",
       "  'i',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'stop',\n",
       "  'thinking',\n",
       "  ',',\n",
       "  'i',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'live',\n",
       "  'without',\n",
       "  'you',\n",
       "  ',',\n",
       "  'i',\n",
       "  'am',\n",
       "  'lonely',\n",
       "  'here',\n",
       "  ',',\n",
       "  'searching',\n",
       "  'you',\n",
       "  'everywhere',\n",
       "  ',',\n",
       "  'life',\n",
       "  'is',\n",
       "  'where',\n",
       "  '...',\n",
       "  '.'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'the',\n",
       "  'time',\n",
       "  'seems',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'here',\n",
       "  ',',\n",
       "  'every',\n",
       "  'where',\n",
       "  'is',\n",
       "  'a',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'depression',\n",
       "  ',',\n",
       "  'impatienty',\n",
       "  'is',\n",
       "  'all',\n",
       "  'around',\n",
       "  ',',\n",
       "  'body',\n",
       "  'is',\n",
       "  'alone',\n",
       "  ',',\n",
       "  'soul',\n",
       "  'is',\n",
       "  'full',\n",
       "  'of',\n",
       "  'thirst',\n",
       "  '.'],\n",
       " ['why',\n",
       "  'not',\n",
       "  'your',\n",
       "  'face',\n",
       "  'get',\n",
       "  'away',\n",
       "  'from',\n",
       "  'my',\n",
       "  'eyes',\n",
       "  'for',\n",
       "  'a',\n",
       "  'moment',\n",
       "  ',',\n",
       "  'i',\n",
       "  'can',\n",
       "  'pass',\n",
       "  'days',\n",
       "  'and',\n",
       "  'nights',\n",
       "  ',',\n",
       "  'but',\n",
       "  'life',\n",
       "  'is',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'pass',\n",
       "  'alone',\n",
       "  ',',\n",
       "  'i',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'say',\n",
       "  'anything',\n",
       "  'to',\n",
       "  'you',\n",
       "  'even',\n",
       "  'if',\n",
       "  'i',\n",
       "  'want',\n",
       "  ',',\n",
       "  'how',\n",
       "  'can',\n",
       "  'i',\n",
       "  'express',\n",
       "  'my',\n",
       "  'grief',\n",
       "  'to',\n",
       "  'you',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'lonely',\n",
       "  'here',\n",
       "  ',',\n",
       "  'searching',\n",
       "  'you',\n",
       "  'everywhere',\n",
       "  ',',\n",
       "  'life',\n",
       "  'is',\n",
       "  'where',\n",
       "  '...',\n",
       "  '.'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'whenever',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'slight',\n",
       "  'sound',\n",
       "  ',',\n",
       "  'it',\n",
       "  'felt',\n",
       "  'that',\n",
       "  'you',\n",
       "  'came',\n",
       "  'here',\n",
       "  ',',\n",
       "  'you',\n",
       "  'scented',\n",
       "  'my',\n",
       "  'life',\n",
       "  ',',\n",
       "  'like',\n",
       "  'a',\n",
       "  'scented',\n",
       "  'rose',\n",
       "  'to',\n",
       "  'me',\n",
       "  ',',\n",
       "  'there',\n",
       "  'was',\n",
       "  'a',\n",
       "  'time',\n",
       "  'when',\n",
       "  'we',\n",
       "  'never',\n",
       "  'got',\n",
       "  'apart',\n",
       "  ',',\n",
       "  'but',\n",
       "  'now',\n",
       "  'the',\n",
       "  'distances',\n",
       "  'in',\n",
       "  'my',\n",
       "  'heart',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'lonely',\n",
       "  'here',\n",
       "  ',',\n",
       "  'searching',\n",
       "  'you',\n",
       "  'everywhere',\n",
       "  ',',\n",
       "  'life',\n",
       "  'is',\n",
       "  'where',\n",
       "  '...',\n",
       "  '.'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'i',\n",
       "  'remember',\n",
       "  'the',\n",
       "  'old',\n",
       "  'memories',\n",
       "  'when',\n",
       "  'i',\n",
       "  'am',\n",
       "  'lonely',\n",
       "  ',',\n",
       "  'these',\n",
       "  'loneliness',\n",
       "  'speaks',\n",
       "  'to',\n",
       "  'me',\n",
       "  ',',\n",
       "  'i',\n",
       "  'cry',\n",
       "  'hidind',\n",
       "  'from',\n",
       "  'everybody',\n",
       "  ',',\n",
       "  'there',\n",
       "  'been',\n",
       "  'a',\n",
       "  'long',\n",
       "  'time',\n",
       "  'since',\n",
       "  'i',\n",
       "  'smiled',\n",
       "  ',',\n",
       "  'now',\n",
       "  'only',\n",
       "  'tears',\n",
       "  'say',\n",
       "  'my',\n",
       "  'story',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'lonely',\n",
       "  'here',\n",
       "  ',',\n",
       "  'searching',\n",
       "  'you',\n",
       "  'everywhere',\n",
       "  ',',\n",
       "  'life',\n",
       "  'is',\n",
       "  'where',\n",
       "  '...',\n",
       "  '.'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'i',\n",
       "  'can',\n",
       "  'see',\n",
       "  'only',\n",
       "  'you',\n",
       "  'wherever',\n",
       "  'i',\n",
       "  'see',\n",
       "  '...',\n",
       "  'i',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'sleep',\n",
       "  ',',\n",
       "  'i',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'stop',\n",
       "  'thinking',\n",
       "  ',',\n",
       "  'i',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'live',\n",
       "  'without',\n",
       "  'you',\n",
       "  '.'],\n",
       " ['--', 'nil', 'HAZEL', 'EYES', '.'],\n",
       " ['close',\n",
       "  'your',\n",
       "  'eyes',\n",
       "  'and',\n",
       "  'imagine',\n",
       "  'a',\n",
       "  'lake',\n",
       "  'without',\n",
       "  'water',\n",
       "  ',',\n",
       "  'imagine',\n",
       "  'a',\n",
       "  'tree',\n",
       "  'without',\n",
       "  'leaves',\n",
       "  ',',\n",
       "  'imagine',\n",
       "  'the',\n",
       "  'moon',\n",
       "  'without',\n",
       "  'stars',\n",
       "  ',',\n",
       "  'imagine',\n",
       "  'a',\n",
       "  'leaf',\n",
       "  'lying',\n",
       "  'worthless',\n",
       "  'on',\n",
       "  'the',\n",
       "  'ground',\n",
       "  ',',\n",
       "  'imagine',\n",
       "  'a',\n",
       "  'body',\n",
       "  'withou',\n",
       "  'HEART',\n",
       "  '.'],\n",
       " ['close',\n",
       "  'your',\n",
       "  'eyes',\n",
       "  'again',\n",
       "  'and',\n",
       "  'imagine',\n",
       "  'me',\n",
       "  'lonely',\n",
       "  ',',\n",
       "  'alone',\n",
       "  'among',\n",
       "  'thousand',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['no-one',\n",
       "  'to',\n",
       "  'share',\n",
       "  'joy',\n",
       "  'and',\n",
       "  'pain',\n",
       "  ',',\n",
       "  'no-true',\n",
       "  'friends',\n",
       "  'and',\n",
       "  'nothing',\n",
       "  'to',\n",
       "  'gain',\n",
       "  ',',\n",
       "  'leading',\n",
       "  'a',\n",
       "  'life',\n",
       "  'which',\n",
       "  'is',\n",
       "  'smooth',\n",
       "  'but',\n",
       "  'dark',\n",
       "  ',',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'forget',\n",
       "  'the',\n",
       "  'memories',\n",
       "  'of',\n",
       "  'morning',\n",
       "  'lark',\n",
       "  '.'],\n",
       " ['close',\n",
       "  'your',\n",
       "  'eyes',\n",
       "  'again',\n",
       "  'imagine',\n",
       "  'yourself',\n",
       "  'standing',\n",
       "  'on',\n",
       "  'a',\n",
       "  'shore',\n",
       "  ',',\n",
       "  'under',\n",
       "  'a',\n",
       "  'palm',\n",
       "  'tree',\n",
       "  ',',\n",
       "  'behind',\n",
       "  'you',\n",
       "  'are',\n",
       "  'the',\n",
       "  'mountains',\n",
       "  ',',\n",
       "  'feeling',\n",
       "  'sad',\n",
       "  'and',\n",
       "  'bore',\n",
       "  '.'],\n",
       " ['waiting',\n",
       "  'for',\n",
       "  'someone',\n",
       "  'to',\n",
       "  'appear',\n",
       "  'from',\n",
       "  'the',\n",
       "  'sea',\n",
       "  ',',\n",
       "  'gives',\n",
       "  'you',\n",
       "  'a',\n",
       "  'blessing',\n",
       "  ',',\n",
       "  'and',\n",
       "  'sets',\n",
       "  'you',\n",
       "  'free',\n",
       "  '.'],\n",
       " ['imagine',\n",
       "  'a',\n",
       "  'flower',\n",
       "  'without',\n",
       "  'its',\n",
       "  'colour',\n",
       "  ',',\n",
       "  'AND',\n",
       "  'THAT',\n",
       "  \"'S\",\n",
       "  'HOW',\n",
       "  'I',\n",
       "  'FEEL',\n",
       "  'WITHOUT',\n",
       "  'YOU',\n",
       "  '.'],\n",
       " ['overcome',\n",
       "  'your',\n",
       "  'grief',\n",
       "  ',',\n",
       "  'stand',\n",
       "  'tall',\n",
       "  'and',\n",
       "  'save',\n",
       "  'the',\n",
       "  'lake',\n",
       "  'to',\n",
       "  'turn',\n",
       "  'barren',\n",
       "  ',',\n",
       "  'save',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'to',\n",
       "  'turn',\n",
       "  'fossil',\n",
       "  ',',\n",
       "  'save',\n",
       "  'the',\n",
       "  'moon',\n",
       "  'to',\n",
       "  'turn',\n",
       "  'alone',\n",
       "  ',',\n",
       "  'save',\n",
       "  'the',\n",
       "  'leaf',\n",
       "  'before',\n",
       "  'anyone',\n",
       "  'steps',\n",
       "  'on',\n",
       "  'it',\n",
       "  ',',\n",
       "  'save',\n",
       "  'the',\n",
       "  'body',\n",
       "  'before',\n",
       "  'it',\n",
       "  'dies',\n",
       "  '...',\n",
       "  '--',\n",
       "  'nil',\n",
       "  'LET',\n",
       "  'IT',\n",
       "  'BE',\n",
       "  'ME',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'bird',\n",
       "  'hibernated',\n",
       "  'for',\n",
       "  'a',\n",
       "  'year',\n",
       "  'or',\n",
       "  'so',\n",
       "  ',',\n",
       "  'her',\n",
       "  'first',\n",
       "  'flight',\n",
       "  ',',\n",
       "  'after',\n",
       "  'her',\n",
       "  'feathers',\n",
       "  'grow',\n",
       "  '.'],\n",
       " ['sparkled',\n",
       "  'from',\n",
       "  'the',\n",
       "  'sunlight',\n",
       "  'were',\n",
       "  'her',\n",
       "  'eyes',\n",
       "  ',',\n",
       "  'she',\n",
       "  'forgot',\n",
       "  'her',\n",
       "  'mainland',\n",
       "  'and',\n",
       "  'she',\n",
       "  'flies',\n",
       "  'and',\n",
       "  'flies',\n",
       "  '.'],\n",
       " ['created',\n",
       "  'new',\n",
       "  'friends',\n",
       "  ',',\n",
       "  'created',\n",
       "  'new',\n",
       "  'foes',\n",
       "  ',',\n",
       "  'memories',\n",
       "  'of',\n",
       "  'her',\n",
       "  'mainland',\n",
       "  'finally',\n",
       "  'goes',\n",
       "  '.'],\n",
       " ['forgot',\n",
       "  'her',\n",
       "  'hometown',\n",
       "  ',',\n",
       "  'forgot',\n",
       "  'her',\n",
       "  'trust',\n",
       "  ',',\n",
       "  'forgot',\n",
       "  'the',\n",
       "  'first',\n",
       "  'book',\n",
       "  'of',\n",
       "  'love',\n",
       "  ',',\n",
       "  'whose',\n",
       "  'love',\n",
       "  'was',\n",
       "  'just',\n",
       "  '.'],\n",
       " ['week',\n",
       "  'gradually',\n",
       "  'passed',\n",
       "  ',',\n",
       "  'eighth',\n",
       "  'day',\n",
       "  'was',\n",
       "  'pleasure',\n",
       "  ',',\n",
       "  'ninth',\n",
       "  'day',\n",
       "  'was',\n",
       "  'fun',\n",
       "  ',',\n",
       "  'tenth',\n",
       "  'day',\n",
       "  'was',\n",
       "  'leisure',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'eleventh',\n",
       "  'day',\n",
       "  'was',\n",
       "  'a',\n",
       "  'pause',\n",
       "  'in',\n",
       "  'her',\n",
       "  'life',\n",
       "  ',',\n",
       "  'she',\n",
       "  'had',\n",
       "  'a',\n",
       "  'pool',\n",
       "  'of',\n",
       "  'memories',\n",
       "  ',',\n",
       "  'in',\n",
       "  'which',\n",
       "  'she',\n",
       "  'dive',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'cried',\n",
       "  'for',\n",
       "  'her',\n",
       "  'friends',\n",
       "  ',',\n",
       "  'she',\n",
       "  'cried',\n",
       "  'for',\n",
       "  'her',\n",
       "  'foes',\n",
       "  ',',\n",
       "  'she',\n",
       "  'cried',\n",
       "  'for',\n",
       "  'her',\n",
       "  'mainland',\n",
       "  'whose',\n",
       "  'memory',\n",
       "  'never',\n",
       "  'goes',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'cried',\n",
       "  'for',\n",
       "  'her',\n",
       "  'hometown',\n",
       "  ',',\n",
       "  'she',\n",
       "  'cried',\n",
       "  'for',\n",
       "  'her',\n",
       "  'trust',\n",
       "  ',',\n",
       "  'she',\n",
       "  'cried',\n",
       "  'for',\n",
       "  'her',\n",
       "  'first',\n",
       "  'love',\n",
       "  ',',\n",
       "  'whose',\n",
       "  'love',\n",
       "  'was',\n",
       "  'just',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'now',\n",
       "  'takes',\n",
       "  'challenges',\n",
       "  ',',\n",
       "  'each',\n",
       "  'day',\n",
       "  'as',\n",
       "  'a',\n",
       "  'goal',\n",
       "  ',',\n",
       "  'feeling',\n",
       "  'hostile',\n",
       "  ',',\n",
       "  'away',\n",
       "  'from',\n",
       "  'her',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['sparkled',\n",
       "  'from',\n",
       "  'the',\n",
       "  'tears',\n",
       "  ',',\n",
       "  'were',\n",
       "  'her',\n",
       "  'eyes',\n",
       "  ',',\n",
       "  'she',\n",
       "  'remembers',\n",
       "  'her',\n",
       "  'mainland',\n",
       "  'and',\n",
       "  'she',\n",
       "  'cries',\n",
       "  'and',\n",
       "  'cries',\n",
       "  ',',\n",
       "  'no',\n",
       "  'true',\n",
       "  'friends',\n",
       "  'and',\n",
       "  'no',\n",
       "  'true',\n",
       "  'foes',\n",
       "  ',',\n",
       "  'memories',\n",
       "  'of',\n",
       "  'her',\n",
       "  'mainland',\n",
       "  'never',\n",
       "  'goes',\n",
       "  '...',\n",
       "  '--',\n",
       "  'nil',\n",
       "  'you',\n",
       "  'can',\n",
       "  'mail',\n",
       "  'me',\n",
       "  'by',\n",
       "  'clicking',\n",
       "  '-',\n",
       "  'urlLink',\n",
       "  'mailto:swapnilmail123@rediffmail.com']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#**********This is too slow**********\n",
    "#**********only 100k characters are allowed, exception if more than that.******\n",
    "#, its hitting a url in background,\n",
    "#need to precompute and store\n",
    "\n",
    "#get_tokens returns a list of list of tokens, i.e. all sentences in tokenized manner.\n",
    "def get_tokens(input_row):\n",
    "    all_tokens = []\n",
    "    with corenlp.CoreNLPClient(annotators=\"tokenize ssplit\".split()) as client:\n",
    "        ann = client.annotate(input_row[0][:100000])\n",
    "\n",
    "        for sentence in ann.sentence:\n",
    "            tokens = [t.word for t in sentence.token]\n",
    "            all_tokens.append(tokens)\n",
    "    return(all_tokens)\n",
    "\n",
    "get_tokens(df_input_text.iloc[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_as_0_1(gender_str):\n",
    "    if gender_str == \"male\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "#get_gender_as_0_1(\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               male\n",
       "age                    16\n",
       "industry          Student\n",
       "horroscope    Sagittarius\n",
       "Name: 4162441, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    It's been a long time coming, but I have made ...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input_text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# learning_rate = 0.01\n",
    "# num_epochs = 10\n",
    "# batch_size = 1\n",
    "# display_step = 1\n",
    "\n",
    "# # Network Parameters\n",
    "# hidden_size = 100      # 1st layer and 2nd layer number of features\n",
    "# input_size = 50 # assuming just word vocab as of now, later it should be 150\n",
    "# num_classes = 2         # Categories: graphics, sci.space and baseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_output.gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_batch(df,i,batch_size):\n",
    "#     batches = []\n",
    "#     results = []\n",
    "#     texts = df_input_text.text[i*batch_size:i*batch_size+batch_size]\n",
    "#     categories = df_output.gender[i*batch_size:i*batch_size+batch_size]\n",
    "#     for text in texts:\n",
    "#         layer = np.zeros(total_words,dtype=float)\n",
    "#         for word in text.split(' '):\n",
    "#             layer[word2index[word.lower()]] += 1\n",
    "\n",
    "#         batches.append(layer)\n",
    "\n",
    "#     for category in categories:\n",
    "#         index_y = -1\n",
    "#         if category == 0:\n",
    "#             index_y = 0\n",
    "#         elif category == 1:\n",
    "#             index_y = 1\n",
    "#         else:\n",
    "#             index_y = 2\n",
    "#         results.append(index_y)\n",
    "\n",
    "\n",
    "#     return np.array(batches),np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "input_size, hidden_size, output_size = 50, 1, 1\n",
    "epochs = 10\n",
    "seq_length = 20\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A layer that converts word to embeddings\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.Tensor([[1,2,3],[2,5,6]]), requires_grad=False)\n",
    "# y = Variable(torch.Tensor(data[1:]).type(dtype), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-64-2def217c4c3e>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-2def217c4c3e>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    def forward(left_word_emb,  current_word_emb , right_word_emb, left_context, right_context): #should the context be passed as well??\u001b[0m\n\u001b[0m                                                                                                                                        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class rcnn(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(rcnn, self).__init__()\n",
    "        #****#,bias=True in below ??\n",
    "        #??? should there be layer for wsl, wsr?\n",
    "        self.layer_sl = nn.Linear(50,50) #semantic left\n",
    "        self.layer_sr = nn.Linear(50,50) #semantic right\n",
    "        self.layer_lc = nn.Linear(50,50) # left word and left context -> left context\n",
    "        self.layer_rc = nn.Linear(50,50) # right word and right context -> right context\n",
    "        self.layer_concat = nn.Linear(150,100,bias=True) # lc, word, rc -> y hidden\n",
    "        self.tanh = nn.tanh() \n",
    "        #******* what should be the maxPool size???\n",
    "        self.layer_maxPool = nn.MaxPool1d(5)\n",
    "        self.layer_linear = nn.Linear(20,2,bias=True)\n",
    "        self.layer_softmax = nn.Softmax()\n",
    "        \n",
    "\n",
    "    def forward(left_word_emb,  current_word_emb , right_word_emb, left_context, right_context): #should the context be passed as well??\n",
    "        #Assuming context is calculated inside the forward function.\n",
    "        left_word_emb = self.self.layer_sl(left_word_emb)\n",
    "        left_context = self.self.layer_lc(left_context)\n",
    "        right_word_emb = self.layer_sr(right_word_emb)\n",
    "        right_context = self.layer_rc(right_context)\n",
    "        \n",
    "        left_context = left_context + left_word_emb\n",
    "        right_context = right_context + right_word_emb\n",
    "        \n",
    "        \n",
    "        left_context = Wl * left_context + Wsl * prev_word #matrix mul?\n",
    "        right_context =  Wr * right_context + Wsr * next_word #matrix mul?\n",
    "        #Multiply by weights here\n",
    "\n",
    "\n",
    "        #concatenate here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#      def forward(self, x):\n",
    "#         out = self.layer_1(x)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.layer_2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.output_layer(out)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward(left_word_emb,  current_word_emb , right_word_emb, left_context, right_context):\n",
    "#     #Multiply by weights here\n",
    "#     Wl * left_context + Wsl * prev_word\n",
    "#     Wr * right_context + Wsr * next_word\n",
    "#     #concatenate here\n",
    "    \n",
    "#     #Further layers\n",
    "    \n",
    "#   xh = torch.cat((input, right_context), 1)\n",
    "#   context_state = torch.tanh(xh.mm(w1))\n",
    "#   out = context_state.mm(w2)\n",
    "#   return  (out, context_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESTINY\n",
      "tensor([ 0.5473,  0.5169,  0.0295,  0.2992,  1.1377,  0.4791,  0.3222,  0.0666,\n",
      "         0.6030,  0.2123,  0.6300,  0.6149, -0.7968,  0.7400,  0.0720,  0.3642,\n",
      "         0.0197, -0.0513,  0.3029,  0.1033, -0.5545,  0.6291, -0.1391,  0.1858,\n",
      "         0.6319, -0.7077, -1.5172, -0.4848,  0.4947, -0.4868,  1.1384,  0.4002,\n",
      "        -0.7497, -0.1265, -0.1704, -0.3409, -0.0326, -0.4719, -0.2089, -0.8535,\n",
      "        -0.1900, -1.1916,  0.0072, -0.1365, -0.5936,  0.6261,  0.3613, -0.5212,\n",
      "        -0.3627, -0.1763])\n",
      "0\n",
      "It\n",
      "tensor([ 0.6118, -0.2207, -0.1090, -0.0530,  0.5080,  0.3468, -0.3356, -0.1915,\n",
      "        -0.0359,  0.1051,  0.0794,  0.2449, -0.4373, -0.3334,  0.5748,  0.6905,\n",
      "         0.2971,  0.0907, -0.5499, -0.4618,  0.1011, -0.0202,  0.2848,  0.0435,\n",
      "         0.4573, -2.0466, -0.5808,  0.6180,  0.6518, -0.5826,  4.0786, -0.2542,\n",
      "        -0.1465, -0.3432, -0.2544, -0.4468,  0.1266,  0.2813,  0.1333, -0.3697,\n",
      "         0.0501, -0.1006, -0.0179,  0.1114, -0.7180,  0.4910, -0.1000, -0.0437,\n",
      "        -0.0979,  0.1681])\n",
      "1\n",
      "So\n",
      "tensor([ 0.6031, -0.3202,  0.0889, -0.5518,  0.5318,  0.0471, -0.3625,  0.0057,\n",
      "        -0.3767,  0.2253, -0.1353,  0.3599, -0.4252,  0.0713,  0.7707,  0.5671,\n",
      "         0.4123,  0.1245,  0.1423, -0.9653, -0.3905,  0.3420,  0.5697,  0.0316,\n",
      "         0.6946, -1.9216, -0.6712,  0.5797,  0.8609, -0.5911,  3.7787,  0.3043,\n",
      "        -0.0431, -0.4240, -0.0639, -0.0668,  0.0620,  0.5633, -0.2234, -0.4739,\n",
      "        -0.4702,  0.0917,  0.1478,  0.6381, -0.1436, -0.0023, -0.3150, -0.2519,\n",
      "        -0.2688,  0.3666])\n",
      "1\n",
      "Today\n",
      "tensor([ 0.0003,  0.4267, -0.0829,  0.2760,  0.6472, -0.9173, -0.6347, -0.2802,\n",
      "        -0.6665, -0.2844, -0.0642, -0.4363, -0.1083, -0.3582,  0.7231,  0.6537,\n",
      "        -0.2957,  0.1201, -0.0300, -0.2059,  0.2002,  0.1642,  0.1520, -0.0249,\n",
      "         0.5289, -1.3625, -0.5604,  0.1778, -0.0910,  0.0975,  3.5102,  0.1063,\n",
      "         0.0656, -0.0808, -0.1255, -0.6993, -0.0151,  0.3935, -0.0028,  0.2063,\n",
      "        -0.4773, -0.1264,  0.2940,  0.1000,  0.0003,  0.6277, -0.4534,  0.3961,\n",
      "         0.0189,  0.1754])\n",
      "0\n",
      "I\n",
      "tensor([ 0.1189,  0.1525, -0.0821, -0.7414,  0.7592, -0.4833, -0.3101,  0.5148,\n",
      "        -0.9871,  0.0006, -0.1504,  0.8377, -1.0797, -0.5146,  1.3188,  0.6201,\n",
      "         0.1378,  0.4711, -0.0729, -0.7268, -0.7412,  0.7526,  0.8818,  0.2956,\n",
      "         1.3548, -2.5701, -1.3523,  0.4588,  1.0068, -1.1856,  3.4737,  0.7790,\n",
      "        -0.7293,  0.2510, -0.2616, -0.3468,  0.5584,  0.7510,  0.4983, -0.2682,\n",
      "        -0.0027, -0.0183, -0.2810,  0.5532,  0.0377,  0.1856, -0.1503, -0.5751,\n",
      "        -0.2667,  0.9212])\n",
      "1\n",
      "Just\n",
      "tensor([ 0.1770,  0.0652,  0.2855, -0.4243,  0.7499, -0.1489, -0.6679,  0.1179,\n",
      "        -0.4541,  0.1854, -0.6511, -0.4344, -0.6010, -0.1132,  0.8522,  0.2533,\n",
      "         0.3133,  0.0591, -0.8875, -0.4655, -0.3010,  0.7069,  0.4508,  0.1471,\n",
      "         0.6895, -1.8490, -0.2301,  0.6738,  1.0314, -0.8230,  3.6701,  0.6259,\n",
      "        -0.1767,  0.2247, -0.0291, -0.2575,  0.1294,  0.4448,  0.5281, -0.3591,\n",
      "        -0.2781,  0.2067,  0.0762,  0.3220, -0.4059,  0.2320,  0.2091, -0.2978,\n",
      "         0.1103,  0.2206])\n",
      "1\n",
      "You\n",
      "tensor([-0.0011,  0.3332,  0.3574, -0.5404,  0.8203, -0.4939, -0.3259,  0.0020,\n",
      "        -0.2383,  0.3555, -0.6065,  0.9893, -0.2179,  0.1124,  1.1494,  0.7328,\n",
      "         0.5118,  0.2929,  0.2839, -1.3590, -0.3795,  0.5094,  0.7071,  0.6294,\n",
      "         1.0534, -2.1756, -1.3204,  0.4000,  1.5741, -1.6600,  3.7721,  0.8695,\n",
      "        -0.8044,  0.1839, -0.3433,  0.0107,  0.2397,  0.0667,  0.7012, -0.7370,\n",
      "         0.2088,  0.1156, -0.1519,  0.8591,  0.2262,  0.1652,  0.3631, -0.4570,\n",
      "        -0.0490,  1.1316])\n",
      "1\n",
      "naked\n",
      "tensor([-0.1580,  0.2656,  0.1606, -0.9311,  0.7477,  0.2287,  0.3393, -0.4760,\n",
      "         0.5814, -0.0277, -0.1178, -0.0887, -0.3810,  0.8642,  0.7122,  0.1977,\n",
      "         0.1785, -0.1221, -0.3938, -0.3840, -0.1105,  1.1061,  0.9808,  0.4778,\n",
      "        -0.2546, -0.8355, -0.6992,  0.9598,  0.5519, -0.4876,  1.2361, -0.0867,\n",
      "         0.2219, -0.2366, -0.8748,  0.7742,  0.3257, -0.5727, -0.4464, -0.9620,\n",
      "         0.1870, -0.1359,  0.3137,  0.8085,  0.5537, -1.2751,  0.1431, -2.0834,\n",
      "         0.2479, -0.7541])\n",
      "0\n",
      "Okay\n",
      "tensor([ 0.1990, -0.7752, -0.1157, -0.3518,  0.4123, -0.6941,  0.1513,  0.3848,\n",
      "        -0.2172,  0.0392,  0.3445,  0.6128, -0.5494,  0.0940,  0.8473,  0.9442,\n",
      "         0.1213,  0.6523,  0.4049, -0.3232, -0.5773,  0.7318,  0.6052,  0.4832,\n",
      "         1.1837, -0.5520, -0.5691,  0.8151,  0.5836, -0.9163,  0.8797,  0.9110,\n",
      "        -0.1712,  1.0019, -0.1781, -0.7781,  0.8182,  0.1593,  0.3100, -0.1575,\n",
      "        -0.2134, -0.4352,  0.1137,  0.3337, -0.3546, -0.0007, -0.0932,  0.4044,\n",
      "         0.2970,  1.1142])\n",
      "1\n",
      "I\n",
      "tensor([ 0.1189,  0.1525, -0.0821, -0.7414,  0.7592, -0.4833, -0.3101,  0.5148,\n",
      "        -0.9871,  0.0006, -0.1504,  0.8377, -1.0797, -0.5146,  1.3188,  0.6201,\n",
      "         0.1378,  0.4711, -0.0729, -0.7268, -0.7412,  0.7526,  0.8818,  0.2956,\n",
      "         1.3548, -2.5701, -1.3523,  0.4588,  1.0068, -1.1856,  3.4737,  0.7790,\n",
      "        -0.7293,  0.2510, -0.2616, -0.3468,  0.5584,  0.7510,  0.4983, -0.2682,\n",
      "        -0.0027, -0.0183, -0.2810,  0.5532,  0.0377,  0.1856, -0.1503, -0.5751,\n",
      "        -0.2667,  0.9212])\n",
      "1\n",
      "Well\n",
      "tensor([ 0.2769,  0.2874, -0.2993, -0.1996,  0.1296,  0.1556, -0.6452, -0.3409,\n",
      "        -0.1183,  0.1580,  0.1397,  0.2487, -0.1590, -0.0334,  0.1190,  0.0765,\n",
      "         0.4526,  0.2649, -0.1916, -0.5677,  0.0293,  0.2174,  0.4341,  0.1498,\n",
      "         0.0758, -1.4453, -0.5839, -0.0461,  0.0662, -0.2642,  3.9650,  0.2520,\n",
      "         0.2485, -0.5052,  0.2581,  0.2868, -0.1799,  0.6288, -0.1204, -0.0421,\n",
      "        -0.0449,  0.1856,  0.1627, -0.0026,  0.1308,  0.2018, -0.2967, -0.0948,\n",
      "        -0.2125,  0.0221])\n",
      "0\n",
      "Sunday\n",
      "tensor([ 0.3027,  0.4737,  0.0146,  0.7597,  0.1044, -0.9705, -1.1058,  1.0341,\n",
      "        -0.4323, -0.8131, -0.7158, -1.5049, -0.7151,  0.2068,  0.8313, -0.0314,\n",
      "        -0.6371, -0.7363, -1.2828,  0.1102,  0.0434,  0.7615,  0.3680,  0.0212,\n",
      "         0.1249, -1.6035,  0.4646,  0.5799, -0.4085,  0.1204,  3.2270,  0.8057,\n",
      "        -0.8170,  0.0899, -0.1907, -0.1954,  0.7164,  0.0685, -0.1252,  0.0982,\n",
      "        -0.0911,  0.3378, -0.4762, -0.5873,  0.4937,  0.6761, -0.5725,  0.5962,\n",
      "         0.4273, -0.5115])\n",
      "1\n",
      "The\n",
      "tensor([ 0.4180,  0.2497, -0.4124,  0.1217,  0.3453, -0.0445, -0.4969, -0.1786,\n",
      "        -0.0007, -0.6566,  0.2784, -0.1477, -0.5568,  0.1466, -0.0095,  0.0117,\n",
      "         0.1020, -0.1279, -0.8443, -0.1218, -0.0168, -0.3328, -0.1552, -0.2313,\n",
      "        -0.1918, -1.8823, -0.7675,  0.0991, -0.4212, -0.1953,  4.0071, -0.1859,\n",
      "        -0.5229, -0.3168,  0.0006,  0.0074,  0.1778, -0.1590,  0.0120, -0.0542,\n",
      "        -0.2987, -0.1575, -0.3476, -0.0456, -0.4425,  0.1878,  0.0028, -0.1841,\n",
      "        -0.1151, -0.7858])\n",
      "1\n",
      "As\n",
      "tensor([ 0.2078,  0.1271, -0.3019, -0.2313,  0.3018,  0.3319, -0.5278, -0.4404,\n",
      "        -0.4835,  0.0350,  0.3478,  0.5457, -0.2066, -0.0837,  0.2462,  0.1593,\n",
      "        -0.0031,  0.3244, -0.4527, -0.2218,  0.0227, -0.0417,  0.3182,  0.0886,\n",
      "        -0.0380, -1.8212, -0.5092, -0.0975, -0.0895,  0.0505,  3.7180, -0.1650,\n",
      "        -0.0787, -0.5710,  0.2042,  0.1341,  0.0743,  0.0875, -0.2544, -0.1501,\n",
      "        -0.1577,  0.3961, -0.2365, -0.0951,  0.0786, -0.0123, -0.4988, -0.3530,\n",
      "         0.0506,  0.0195])\n",
      "0\n",
      "two\n",
      "tensor([ 0.5829,  0.3626,  0.3406,  0.3642,  0.3434,  0.7939, -0.9362,  0.1143,\n",
      "        -0.6301, -0.5552, -0.2871, -0.4714, -0.7567,  0.6387,  0.2248, -0.6465,\n",
      "        -0.0743, -0.3490, -0.9729, -0.5398,  0.0152,  0.2448,  0.6266,  0.0704,\n",
      "        -0.5163, -1.2004,  0.3122, -0.4405, -0.2987, -0.5633,  4.0220,  0.3846,\n",
      "        -0.0285,  0.0687,  1.0746,  0.4831,  0.2475,  0.2280, -0.3574,  0.4039,\n",
      "        -0.5474,  0.1524,  0.4100,  0.1570,  0.0078, -0.0151, -0.2865, -0.1616,\n",
      "        -0.3517, -0.8256])\n",
      "1\n",
      "It\n",
      "tensor([ 0.6118, -0.2207, -0.1090, -0.0530,  0.5080,  0.3468, -0.3356, -0.1915,\n",
      "        -0.0359,  0.1051,  0.0794,  0.2449, -0.4373, -0.3334,  0.5748,  0.6905,\n",
      "         0.2971,  0.0907, -0.5499, -0.4618,  0.1011, -0.0202,  0.2848,  0.0435,\n",
      "         0.4573, -2.0466, -0.5808,  0.6180,  0.6518, -0.5826,  4.0786, -0.2542,\n",
      "        -0.1465, -0.3432, -0.2544, -0.4468,  0.1266,  0.2813,  0.1333, -0.3697,\n",
      "         0.0501, -0.1006, -0.0179,  0.1114, -0.7180,  0.4910, -0.1000, -0.0437,\n",
      "        -0.0979,  0.1681])\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "tensor([-0.4385,  1.1905, -0.1163, -0.9594,  0.4589,  1.4150, -0.6760, -0.8434,\n",
      "        -0.7357,  0.2872,  0.6475, -0.3622,  0.1149, -0.3402,  1.1601,  0.2720,\n",
      "        -0.4529,  0.2052, -0.8096,  0.5534, -0.2132,  0.9178,  0.6683,  0.0559,\n",
      "         0.3971, -0.9000, -1.1099, -0.9121,  0.3440,  0.4425,  2.9440,  0.2597,\n",
      "         0.2412, -0.6596,  0.7578, -0.1379,  0.1987,  0.2505,  0.4246, -0.1881,\n",
      "        -1.0105, -0.4946,  0.5689,  0.7545, -0.4724, -0.4388,  0.1331, -0.9140,\n",
      "        -0.0862, -0.1799])\n",
      "1\n",
      "3\n",
      "tensor([-0.3091,  0.8330,  0.8006,  0.5646,  0.4235,  0.6813, -0.1452, -0.3080,\n",
      "        -0.7287, -0.4448, -0.0039, -0.3477, -0.2533, -0.4465,  0.5950, -0.6712,\n",
      "        -0.4747, -0.1665, -1.7268,  0.4528,  0.2017, -0.7969,  1.2426,  0.3237,\n",
      "        -0.7365, -0.4267,  0.9334, -0.5727,  0.3809, -0.4772,  3.5561,  0.3152,\n",
      "        -0.3565,  0.6038,  0.4639, -0.2327,  0.5828,  0.2207,  0.7352, -0.5468,\n",
      "         0.5000, -0.6742,  0.6379, -1.0965, -0.5135,  1.2085,  0.2982, -0.7595,\n",
      "         0.5024,  0.3566])\n",
      "0\n",
      "I\n",
      "tensor([ 0.1189,  0.1525, -0.0821, -0.7414,  0.7592, -0.4833, -0.3101,  0.5148,\n",
      "        -0.9871,  0.0006, -0.1504,  0.8377, -1.0797, -0.5146,  1.3188,  0.6201,\n",
      "         0.1378,  0.4711, -0.0729, -0.7268, -0.7412,  0.7526,  0.8818,  0.2956,\n",
      "         1.3548, -2.5701, -1.3523,  0.4588,  1.0068, -1.1856,  3.4737,  0.7790,\n",
      "        -0.7293,  0.2510, -0.2616, -0.3468,  0.5584,  0.7510,  0.4983, -0.2682,\n",
      "        -0.0027, -0.0183, -0.2810,  0.5532,  0.0377,  0.1856, -0.1503, -0.5751,\n",
      "        -0.2667,  0.9212])\n",
      "0\n",
      "^\n",
      "tensor([-0.4202,  1.1280,  0.7560,  0.9625,  0.0415, -0.1065,  0.7627, -0.4719,\n",
      "        -0.3539, -0.2600, -0.2714,  0.4490, -0.0545, -0.4251, -0.0143, -0.1491,\n",
      "        -0.3274,  0.0119, -0.0935,  0.2401, -0.8820, -0.5325,  1.4996,  0.3761,\n",
      "        -0.1141,  1.1531, -0.2622, -0.0638,  0.2408,  0.0816,  0.2472, -0.1729,\n",
      "        -0.4888,  1.1017, -0.1612, -0.8406,  0.7106, -0.4515,  0.5303, -0.0961,\n",
      "         0.8146, -1.2253, -0.1200,  0.3410, -0.1497,  0.8095,  0.1168, -0.0532,\n",
      "         0.4063,  0.8888])\n",
      "1\n",
      "I\n",
      "tensor([ 0.1189,  0.1525, -0.0821, -0.7414,  0.7592, -0.4833, -0.3101,  0.5148,\n",
      "        -0.9871,  0.0006, -0.1504,  0.8377, -1.0797, -0.5146,  1.3188,  0.6201,\n",
      "         0.1378,  0.4711, -0.0729, -0.7268, -0.7412,  0.7526,  0.8818,  0.2956,\n",
      "         1.3548, -2.5701, -1.3523,  0.4588,  1.0068, -1.1856,  3.4737,  0.7790,\n",
      "        -0.7293,  0.2510, -0.2616, -0.3468,  0.5584,  0.7510,  0.4983, -0.2682,\n",
      "        -0.0027, -0.0183, -0.2810,  0.5532,  0.0377,  0.1856, -0.1503, -0.5751,\n",
      "        -0.2667,  0.9212])\n",
      "1\n",
      "WHATS\n",
      "tensor([ 0.1920, -0.5046,  0.1727, -0.4848, -0.3638, -1.1720,  0.2629, -0.0272,\n",
      "         0.6798,  0.3589, -0.6311, -0.0368, -0.8607,  0.8387,  0.1289,  0.3833,\n",
      "         0.3625, -0.0039,  0.8439,  0.4478, -0.2565,  0.1342,  0.6297,  0.9656,\n",
      "         0.7844,  0.0606, -1.6061,  0.2893,  1.0591, -0.6604, -0.7201,  0.5200,\n",
      "        -0.5218,  0.5118,  0.1730, -0.1158, -0.1510,  0.1164,  0.5778,  0.6315,\n",
      "        -0.5270, -0.5690, -0.1139,  0.4323,  0.4049,  0.3630,  1.3365,  0.5145,\n",
      "         0.2498,  0.5355])\n",
      "0\n",
      "Today\n",
      "tensor([ 0.0003,  0.4267, -0.0829,  0.2760,  0.6472, -0.9173, -0.6347, -0.2802,\n",
      "        -0.6665, -0.2844, -0.0642, -0.4363, -0.1083, -0.3582,  0.7231,  0.6537,\n",
      "        -0.2957,  0.1201, -0.0300, -0.2059,  0.2002,  0.1642,  0.1520, -0.0249,\n",
      "         0.5289, -1.3625, -0.5604,  0.1778, -0.0910,  0.0975,  3.5102,  0.1063,\n",
      "         0.0656, -0.0808, -0.1255, -0.6993, -0.0151,  0.3935, -0.0028,  0.2063,\n",
      "        -0.4773, -0.1264,  0.2940,  0.1000,  0.0003,  0.6277, -0.4534,  0.3961,\n",
      "         0.0189,  0.1754])\n",
      "1\n",
      "Ok\n",
      "tensor([-0.5365, -0.0724,  0.2418,  0.0990,  0.1843, -0.8676,  0.0819,  0.4047,\n",
      "        -0.4051,  0.4745, -0.1687,  0.3894, -0.1692,  0.1661,  0.7354,  0.8361,\n",
      "         0.0268,  0.5696,  0.4199, -0.2330, -0.5884,  0.5495,  0.7164,  0.2245,\n",
      "         1.0043, -1.5036, -0.7852,  0.7336,  0.4161, -1.6782,  1.9156,  0.2659,\n",
      "        -0.4155,  0.9797, -0.0604, -0.7442,  0.6166, -0.0231,  0.7738, -0.6527,\n",
      "        -0.2002, -0.2479,  0.0470,  0.3141,  0.3260, -0.2448,  0.1683,  0.0978,\n",
      "         0.1239,  1.1584])\n",
      "0\n",
      "Old\n",
      "tensor([-0.4853,  0.9838, -0.2903, -0.3308,  0.7467,  0.5992, -1.4261,  0.0849,\n",
      "        -0.2533, -0.1080, -0.0736, -0.2404, -0.6001,  0.2772,  0.6128,  0.0773,\n",
      "        -0.4800,  0.5070,  0.1302,  0.6652, -0.8458,  0.9411, -1.0953,  0.4036,\n",
      "         0.1651, -2.5206, -0.1682,  0.2054,  0.2047,  0.0744,  2.7209, -0.7090,\n",
      "        -0.0495,  0.9631,  0.7211,  0.5529, -0.1386,  0.5980,  0.5836, -0.4216,\n",
      "        -0.2174,  0.3613,  0.1828,  0.3306,  0.5875,  0.1003, -0.1622, -0.9594,\n",
      "         0.0384, -0.7330])\n",
      "1\n",
      "Epoch: 0 loss 0\n",
      "DESTINY\n",
      "tensor([ 0.5473,  0.5169,  0.0295,  0.2992,  1.1377,  0.4791,  0.3222,  0.0666,\n",
      "         0.6030,  0.2123,  0.6300,  0.6149, -0.7968,  0.7400,  0.0720,  0.3642,\n",
      "         0.0197, -0.0513,  0.3029,  0.1033, -0.5545,  0.6291, -0.1391,  0.1858,\n",
      "         0.6319, -0.7077, -1.5172, -0.4848,  0.4947, -0.4868,  1.1384,  0.4002,\n",
      "        -0.7497, -0.1265, -0.1704, -0.3409, -0.0326, -0.4719, -0.2089, -0.8535,\n",
      "        -0.1900, -1.1916,  0.0072, -0.1365, -0.5936,  0.6261,  0.3613, -0.5212,\n",
      "        -0.3627, -0.1763])\n",
      "0\n",
      "It\n",
      "tensor([ 0.6118, -0.2207, -0.1090, -0.0530,  0.5080,  0.3468, -0.3356, -0.1915,\n",
      "        -0.0359,  0.1051,  0.0794,  0.2449, -0.4373, -0.3334,  0.5748,  0.6905,\n",
      "         0.2971,  0.0907, -0.5499, -0.4618,  0.1011, -0.0202,  0.2848,  0.0435,\n",
      "         0.4573, -2.0466, -0.5808,  0.6180,  0.6518, -0.5826,  4.0786, -0.2542,\n",
      "        -0.1465, -0.3432, -0.2544, -0.4468,  0.1266,  0.2813,  0.1333, -0.3697,\n",
      "         0.0501, -0.1006, -0.0179,  0.1114, -0.7180,  0.4910, -0.1000, -0.0437,\n",
      "        -0.0979,  0.1681])\n",
      "1\n",
      "So\n",
      "tensor([ 0.6031, -0.3202,  0.0889, -0.5518,  0.5318,  0.0471, -0.3625,  0.0057,\n",
      "        -0.3767,  0.2253, -0.1353,  0.3599, -0.4252,  0.0713,  0.7707,  0.5671,\n",
      "         0.4123,  0.1245,  0.1423, -0.9653, -0.3905,  0.3420,  0.5697,  0.0316,\n",
      "         0.6946, -1.9216, -0.6712,  0.5797,  0.8609, -0.5911,  3.7787,  0.3043,\n",
      "        -0.0431, -0.4240, -0.0639, -0.0668,  0.0620,  0.5633, -0.2234, -0.4739,\n",
      "        -0.4702,  0.0917,  0.1478,  0.6381, -0.1436, -0.0023, -0.3150, -0.2519,\n",
      "        -0.2688,  0.3666])\n",
      "1\n",
      "Today\n",
      "tensor([ 0.0003,  0.4267, -0.0829,  0.2760,  0.6472, -0.9173, -0.6347, -0.2802,\n",
      "        -0.6665, -0.2844, -0.0642, -0.4363, -0.1083, -0.3582,  0.7231,  0.6537,\n",
      "        -0.2957,  0.1201, -0.0300, -0.2059,  0.2002,  0.1642,  0.1520, -0.0249,\n",
      "         0.5289, -1.3625, -0.5604,  0.1778, -0.0910,  0.0975,  3.5102,  0.1063,\n",
      "         0.0656, -0.0808, -0.1255, -0.6993, -0.0151,  0.3935, -0.0028,  0.2063,\n",
      "        -0.4773, -0.1264,  0.2940,  0.1000,  0.0003,  0.6277, -0.4534,  0.3961,\n",
      "         0.0189,  0.1754])\n",
      "0\n",
      "I\n",
      "tensor([ 0.1189,  0.1525, -0.0821, -0.7414,  0.7592, -0.4833, -0.3101,  0.5148,\n",
      "        -0.9871,  0.0006, -0.1504,  0.8377, -1.0797, -0.5146,  1.3188,  0.6201,\n",
      "         0.1378,  0.4711, -0.0729, -0.7268, -0.7412,  0.7526,  0.8818,  0.2956,\n",
      "         1.3548, -2.5701, -1.3523,  0.4588,  1.0068, -1.1856,  3.4737,  0.7790,\n",
      "        -0.7293,  0.2510, -0.2616, -0.3468,  0.5584,  0.7510,  0.4983, -0.2682,\n",
      "        -0.0027, -0.0183, -0.2810,  0.5532,  0.0377,  0.1856, -0.1503, -0.5751,\n",
      "        -0.2667,  0.9212])\n",
      "1\n",
      "Just\n",
      "tensor([ 0.1770,  0.0652,  0.2855, -0.4243,  0.7499, -0.1489, -0.6679,  0.1179,\n",
      "        -0.4541,  0.1854, -0.6511, -0.4344, -0.6010, -0.1132,  0.8522,  0.2533,\n",
      "         0.3133,  0.0591, -0.8875, -0.4655, -0.3010,  0.7069,  0.4508,  0.1471,\n",
      "         0.6895, -1.8490, -0.2301,  0.6738,  1.0314, -0.8230,  3.6701,  0.6259,\n",
      "        -0.1767,  0.2247, -0.0291, -0.2575,  0.1294,  0.4448,  0.5281, -0.3591,\n",
      "        -0.2781,  0.2067,  0.0762,  0.3220, -0.4059,  0.2320,  0.2091, -0.2978,\n",
      "         0.1103,  0.2206])\n",
      "1\n",
      "You\n",
      "tensor([-0.0011,  0.3332,  0.3574, -0.5404,  0.8203, -0.4939, -0.3259,  0.0020,\n",
      "        -0.2383,  0.3555, -0.6065,  0.9893, -0.2179,  0.1124,  1.1494,  0.7328,\n",
      "         0.5118,  0.2929,  0.2839, -1.3590, -0.3795,  0.5094,  0.7071,  0.6294,\n",
      "         1.0534, -2.1756, -1.3204,  0.4000,  1.5741, -1.6600,  3.7721,  0.8695,\n",
      "        -0.8044,  0.1839, -0.3433,  0.0107,  0.2397,  0.0667,  0.7012, -0.7370,\n",
      "         0.2088,  0.1156, -0.1519,  0.8591,  0.2262,  0.1652,  0.3631, -0.4570,\n",
      "        -0.0490,  1.1316])\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naked\n",
      "tensor([-0.1580,  0.2656,  0.1606, -0.9311,  0.7477,  0.2287,  0.3393, -0.4760,\n",
      "         0.5814, -0.0277, -0.1178, -0.0887, -0.3810,  0.8642,  0.7122,  0.1977,\n",
      "         0.1785, -0.1221, -0.3938, -0.3840, -0.1105,  1.1061,  0.9808,  0.4778,\n",
      "        -0.2546, -0.8355, -0.6992,  0.9598,  0.5519, -0.4876,  1.2361, -0.0867,\n",
      "         0.2219, -0.2366, -0.8748,  0.7742,  0.3257, -0.5727, -0.4464, -0.9620,\n",
      "         0.1870, -0.1359,  0.3137,  0.8085,  0.5537, -1.2751,  0.1431, -2.0834,\n",
      "         0.2479, -0.7541])\n",
      "0\n",
      "Okay\n",
      "tensor([ 0.1990, -0.7752, -0.1157, -0.3518,  0.4123, -0.6941,  0.1513,  0.3848,\n",
      "        -0.2172,  0.0392,  0.3445,  0.6128, -0.5494,  0.0940,  0.8473,  0.9442,\n",
      "         0.1213,  0.6523,  0.4049, -0.3232, -0.5773,  0.7318,  0.6052,  0.4832,\n",
      "         1.1837, -0.5520, -0.5691,  0.8151,  0.5836, -0.9163,  0.8797,  0.9110,\n",
      "        -0.1712,  1.0019, -0.1781, -0.7781,  0.8182,  0.1593,  0.3100, -0.1575,\n",
      "        -0.2134, -0.4352,  0.1137,  0.3337, -0.3546, -0.0007, -0.0932,  0.4044,\n",
      "         0.2970,  1.1142])\n",
      "1\n",
      "I\n",
      "tensor([ 0.1189,  0.1525, -0.0821, -0.7414,  0.7592, -0.4833, -0.3101,  0.5148,\n",
      "        -0.9871,  0.0006, -0.1504,  0.8377, -1.0797, -0.5146,  1.3188,  0.6201,\n",
      "         0.1378,  0.4711, -0.0729, -0.7268, -0.7412,  0.7526,  0.8818,  0.2956,\n",
      "         1.3548, -2.5701, -1.3523,  0.4588,  1.0068, -1.1856,  3.4737,  0.7790,\n",
      "        -0.7293,  0.2510, -0.2616, -0.3468,  0.5584,  0.7510,  0.4983, -0.2682,\n",
      "        -0.0027, -0.0183, -0.2810,  0.5532,  0.0377,  0.1856, -0.1503, -0.5751,\n",
      "        -0.2667,  0.9212])\n",
      "1\n",
      "Well\n",
      "tensor([ 0.2769,  0.2874, -0.2993, -0.1996,  0.1296,  0.1556, -0.6452, -0.3409,\n",
      "        -0.1183,  0.1580,  0.1397,  0.2487, -0.1590, -0.0334,  0.1190,  0.0765,\n",
      "         0.4526,  0.2649, -0.1916, -0.5677,  0.0293,  0.2174,  0.4341,  0.1498,\n",
      "         0.0758, -1.4453, -0.5839, -0.0461,  0.0662, -0.2642,  3.9650,  0.2520,\n",
      "         0.2485, -0.5052,  0.2581,  0.2868, -0.1799,  0.6288, -0.1204, -0.0421,\n",
      "        -0.0449,  0.1856,  0.1627, -0.0026,  0.1308,  0.2018, -0.2967, -0.0948,\n",
      "        -0.2125,  0.0221])\n",
      "0\n",
      "Sunday\n",
      "tensor([ 0.3027,  0.4737,  0.0146,  0.7597,  0.1044, -0.9705, -1.1058,  1.0341,\n",
      "        -0.4323, -0.8131, -0.7158, -1.5049, -0.7151,  0.2068,  0.8313, -0.0314,\n",
      "        -0.6371, -0.7363, -1.2828,  0.1102,  0.0434,  0.7615,  0.3680,  0.0212,\n",
      "         0.1249, -1.6035,  0.4646,  0.5799, -0.4085,  0.1204,  3.2270,  0.8057,\n",
      "        -0.8170,  0.0899, -0.1907, -0.1954,  0.7164,  0.0685, -0.1252,  0.0982,\n",
      "        -0.0911,  0.3378, -0.4762, -0.5873,  0.4937,  0.6761, -0.5725,  0.5962,\n",
      "         0.4273, -0.5115])\n",
      "1\n",
      "The\n",
      "tensor([ 0.4180,  0.2497, -0.4124,  0.1217,  0.3453, -0.0445, -0.4969, -0.1786,\n",
      "        -0.0007, -0.6566,  0.2784, -0.1477, -0.5568,  0.1466, -0.0095,  0.0117,\n",
      "         0.1020, -0.1279, -0.8443, -0.1218, -0.0168, -0.3328, -0.1552, -0.2313,\n",
      "        -0.1918, -1.8823, -0.7675,  0.0991, -0.4212, -0.1953,  4.0071, -0.1859,\n",
      "        -0.5229, -0.3168,  0.0006,  0.0074,  0.1778, -0.1590,  0.0120, -0.0542,\n",
      "        -0.2987, -0.1575, -0.3476, -0.0456, -0.4425,  0.1878,  0.0028, -0.1841,\n",
      "        -0.1151, -0.7858])\n",
      "1\n",
      "As\n",
      "tensor([ 0.2078,  0.1271, -0.3019, -0.2313,  0.3018,  0.3319, -0.5278, -0.4404,\n",
      "        -0.4835,  0.0350,  0.3478,  0.5457, -0.2066, -0.0837,  0.2462,  0.1593,\n",
      "        -0.0031,  0.3244, -0.4527, -0.2218,  0.0227, -0.0417,  0.3182,  0.0886,\n",
      "        -0.0380, -1.8212, -0.5092, -0.0975, -0.0895,  0.0505,  3.7180, -0.1650,\n",
      "        -0.0787, -0.5710,  0.2042,  0.1341,  0.0743,  0.0875, -0.2544, -0.1501,\n",
      "        -0.1577,  0.3961, -0.2365, -0.0951,  0.0786, -0.0123, -0.4988, -0.3530,\n",
      "         0.0506,  0.0195])\n",
      "0\n",
      "two\n",
      "tensor([ 0.5829,  0.3626,  0.3406,  0.3642,  0.3434,  0.7939, -0.9362,  0.1143,\n",
      "        -0.6301, -0.5552, -0.2871, -0.4714, -0.7567,  0.6387,  0.2248, -0.6465,\n",
      "        -0.0743, -0.3490, -0.9729, -0.5398,  0.0152,  0.2448,  0.6266,  0.0704,\n",
      "        -0.5163, -1.2004,  0.3122, -0.4405, -0.2987, -0.5633,  4.0220,  0.3846,\n",
      "        -0.0285,  0.0687,  1.0746,  0.4831,  0.2475,  0.2280, -0.3574,  0.4039,\n",
      "        -0.5474,  0.1524,  0.4100,  0.1570,  0.0078, -0.0151, -0.2865, -0.1616,\n",
      "        -0.3517, -0.8256])\n",
      "1\n",
      "It\n",
      "tensor([ 0.6118, -0.2207, -0.1090, -0.0530,  0.5080,  0.3468, -0.3356, -0.1915,\n",
      "        -0.0359,  0.1051,  0.0794,  0.2449, -0.4373, -0.3334,  0.5748,  0.6905,\n",
      "         0.2971,  0.0907, -0.5499, -0.4618,  0.1011, -0.0202,  0.2848,  0.0435,\n",
      "         0.4573, -2.0466, -0.5808,  0.6180,  0.6518, -0.5826,  4.0786, -0.2542,\n",
      "        -0.1465, -0.3432, -0.2544, -0.4468,  0.1266,  0.2813,  0.1333, -0.3697,\n",
      "         0.0501, -0.1006, -0.0179,  0.1114, -0.7180,  0.4910, -0.1000, -0.0437,\n",
      "        -0.0979,  0.1681])\n",
      "1\n",
      "Age\n",
      "tensor([-0.4385,  1.1905, -0.1163, -0.9594,  0.4589,  1.4150, -0.6760, -0.8434,\n",
      "        -0.7357,  0.2872,  0.6475, -0.3622,  0.1149, -0.3402,  1.1601,  0.2720,\n",
      "        -0.4529,  0.2052, -0.8096,  0.5534, -0.2132,  0.9178,  0.6683,  0.0559,\n",
      "         0.3971, -0.9000, -1.1099, -0.9121,  0.3440,  0.4425,  2.9440,  0.2597,\n",
      "         0.2412, -0.6596,  0.7578, -0.1379,  0.1987,  0.2505,  0.4246, -0.1881,\n",
      "        -1.0105, -0.4946,  0.5689,  0.7545, -0.4724, -0.4388,  0.1331, -0.9140,\n",
      "        -0.0862, -0.1799])\n",
      "1\n",
      "3\n",
      "tensor([-0.3091,  0.8330,  0.8006,  0.5646,  0.4235,  0.6813, -0.1452, -0.3080,\n",
      "        -0.7287, -0.4448, -0.0039, -0.3477, -0.2533, -0.4465,  0.5950, -0.6712,\n",
      "        -0.4747, -0.1665, -1.7268,  0.4528,  0.2017, -0.7969,  1.2426,  0.3237,\n",
      "        -0.7365, -0.4267,  0.9334, -0.5727,  0.3809, -0.4772,  3.5561,  0.3152,\n",
      "        -0.3565,  0.6038,  0.4639, -0.2327,  0.5828,  0.2207,  0.7352, -0.5468,\n",
      "         0.5000, -0.6742,  0.6379, -1.0965, -0.5135,  1.2085,  0.2982, -0.7595,\n",
      "         0.5024,  0.3566])\n",
      "0\n",
      "I\n",
      "tensor([ 0.1189,  0.1525, -0.0821, -0.7414,  0.7592, -0.4833, -0.3101,  0.5148,\n",
      "        -0.9871,  0.0006, -0.1504,  0.8377, -1.0797, -0.5146,  1.3188,  0.6201,\n",
      "         0.1378,  0.4711, -0.0729, -0.7268, -0.7412,  0.7526,  0.8818,  0.2956,\n",
      "         1.3548, -2.5701, -1.3523,  0.4588,  1.0068, -1.1856,  3.4737,  0.7790,\n",
      "        -0.7293,  0.2510, -0.2616, -0.3468,  0.5584,  0.7510,  0.4983, -0.2682,\n",
      "        -0.0027, -0.0183, -0.2810,  0.5532,  0.0377,  0.1856, -0.1503, -0.5751,\n",
      "        -0.2667,  0.9212])\n",
      "0\n",
      "^\n",
      "tensor([-0.4202,  1.1280,  0.7560,  0.9625,  0.0415, -0.1065,  0.7627, -0.4719,\n",
      "        -0.3539, -0.2600, -0.2714,  0.4490, -0.0545, -0.4251, -0.0143, -0.1491,\n",
      "        -0.3274,  0.0119, -0.0935,  0.2401, -0.8820, -0.5325,  1.4996,  0.3761,\n",
      "        -0.1141,  1.1531, -0.2622, -0.0638,  0.2408,  0.0816,  0.2472, -0.1729,\n",
      "        -0.4888,  1.1017, -0.1612, -0.8406,  0.7106, -0.4515,  0.5303, -0.0961,\n",
      "         0.8146, -1.2253, -0.1200,  0.3410, -0.1497,  0.8095,  0.1168, -0.0532,\n",
      "         0.4063,  0.8888])\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-b2ed9fa4fcf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#needs to be run for each word in a sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#assume only first word for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0minput_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_input_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#all sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0minput_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;31m# glove embedding of first word of first sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-7dc04a801ddc>\u001b[0m in \u001b[0;36mget_tokens\u001b[0;34m(input_row)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mall_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcorenlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoreNLPClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tokenize ssplit\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/corenlp/client.py\u001b[0m in \u001b[0;36mannotate\u001b[0;34m(self, text, annotators, properties)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;34m'serializer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             })\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mparseFromDelimitedString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/corenlp/client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, buf, properties)\u001b[0m\n\u001b[1;32m    155\u001b[0m             r = requests.post(self.endpoint,\n\u001b[1;32m    156\u001b[0m                               \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'properties'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                               data=buf, headers={'content-type': ctype})\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \"\"\"\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "  total_loss = 0\n",
    "  context_state = None #Variable(torch.zeros((1, hidden_size)).type(dtype), requires_grad=True)\n",
    "  for j in range(0,df_input_text.text.size):\n",
    "    #needs to be run for each word in a sentence\n",
    "    #assume only first word for now\n",
    "    input_sentences = get_tokens(df_input_text.iloc[j]) #all sentences, can do ravel instead \n",
    "    input = glove[ input_sentences[0][0].lower() ] # glove embedding of first word of first sentence\n",
    "    print(input_sentences[0][0])\n",
    "    print(input)\n",
    "    target = get_gender_as_0_1( df_output.iloc[j].gender)\n",
    "    print(target)\n",
    "#     (pred, context_state) = forward(input, context_state, w1, w2)\n",
    "#     loss = (pred - target).pow(2).sum()/2\n",
    "#     total_loss += loss\n",
    "#     loss.backward()\n",
    "#     w1.data -= lr * w1.grad.data\n",
    "#     w2.data -= lr * w2.grad.data\n",
    "#     w1.grad.data.zero_()\n",
    "#     w2.grad.data.zero_()\n",
    "#     context_state = Variable(context_state.data)\n",
    "  if i % 10 == 0:\n",
    "     print(\"Epoch: {} loss {}\".format(i, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove[\"mailto:abc@abc.com\"] #unknowns come out as zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
